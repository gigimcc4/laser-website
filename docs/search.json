[
  {
    "objectID": "curriculum-network-analysis.html",
    "href": "curriculum-network-analysis.html",
    "title": "Social Network Analysis",
    "section": "",
    "text": "Although social network analysis (SNA) and its educational antecedents date back to the early 1900s, the popularity of social networking sites like Twitter and Facebook have raised awareness of, and renewed interests in, social networks and their influence. As the use of digital resources continues to expand in education, data collected by these educational technologies has also greatly facilitated the application of network analysis to teaching and learning. The SNA modules are designed to prepare STEM education researchers to apply network analysis in order to better understand and improve student learning and the contexts in which learning occurs. The presentations, readings, and case studies for each module draw from the excellent book, Social Network Analysis and Education (Carolan 2014). Collectively, the modules provide education researchers with an overview of social network theory, examples of network analysis in STEM educational contexts, and applied experience with widely adopted tools and techniques.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-1-network-analysis-for-newbies",
    "href": "curriculum-network-analysis.html#module-1-network-analysis-for-newbies",
    "title": "Social Network Analysis",
    "section": "Module 1: Network Analysis for Newbies",
    "text": "Module 1: Network Analysis for Newbies\nThe first module is a gentle introduction to data collection, management and visualization. The focus of our Essential Readings and case study in this lab is to help LASER Scholars gain a general understanding of key SNA concepts and terminology, as well as develop a basic comfort level with representing networks visually. Our SNA Case Study: Who’s Friends with Who in Middle School is guided by the work of Pittinsky and Carolan Pittinsky and Carolan (2008) and compares teacher perceptions and student reports of classroom middle school friendship and helps reinforce the importance of treating behavioral and cognitive classroom friendship networks and ties as distinct. Finally, the Intro to SNA Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nAn Introduction to Social Network Analysis\n\n\n\nCode Along\nData Structures & Sociograms in R | Python\n\n\n\nReadings &\nReflection\nBackground and Basic Concepts\n\n\n\nCase Study\nWho’s Friends with Who in Middle School | R Key | Python Key\n\n\n\nBadge\nIntro to SNA",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-2-network-management-measurement",
    "href": "curriculum-network-analysis.html#module-2-network-management-measurement",
    "title": "Social Network Analysis",
    "section": "Module 2: Network Management & Measurement",
    "text": "Module 2: Network Management & Measurement\nModule 2 moves beyond basic concepts of network analysis and takes a closer look at the collection, management, and measurement of network data. Our Essential Readings examine the different levels at which social networks can be analyzed, as well as common network measures for describing properties of complete networks. Our Case Study: A Tale of Two MOOCs is based on a study by Kellogg, Booth, and Oliver (2014) and compares discussion networks from two courses using an open educational dataset prepared by Kellogg and Edelmann (2015) as part of the Friday Institute’s work around Massively Open Online Courses for Educators (MOOC-Eds). Finally, the Measurement Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nData Collection & Quality\n\n\n\nCode Along\nDensity, Reciprocity, & Centrality\n\n\n\nReadings &\nReflection\nData Management & Network Measurement\n\n\n\nCase Study\nA Tale of Two MOOC (Answer Key)\n\n\n\nBadge\nNetwork Measurement Badge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-3-groups-positions-egocentric-analysis",
    "href": "curriculum-network-analysis.html#module-3-groups-positions-egocentric-analysis",
    "title": "Social Network Analysis",
    "section": "Module 3: Groups, Positions, & Egocentric Analysis",
    "text": "Module 3: Groups, Positions, & Egocentric Analysis\nModule 3 shifts the focus from complete network analysis and zooms in on methods and measures for analyzing groups, positions, and individual actors. Our Essential Readings and case study explore both “top-down” and “bottom-up” approaches to identify a network’s groups and extend measures introduced in the previous lab to identify individuals central to the network. Our SNA Case Study: Hashtag Common Core is inspired by the work of Supovitz et al. (2017) who examined groups and key actors that emerged during the intense Twitter debate surrounding the Common Core State Standards. You can learn more about their work on the expansive and interactive website for the #COMMONCORE Project. Finally, the Groups & Egos Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nGroup Identification in Networks\n\n\n\nCode Along\nComponents, Cliques & Key Actors\n\n\n\nReadings &\nDiscussion\nGroups, Positions, and Egocentric Analysis\n\n\n\nCase Study\nHashtag Common Core (Answer Key)\n\n\n\nBadge\nGroups & Egos",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-4-statistical-inference-network-models",
    "href": "curriculum-network-analysis.html#module-4-statistical-inference-network-models",
    "title": "Social Network Analysis",
    "section": "Module 4: Statistical Inference & Network Models",
    "text": "Module 4: Statistical Inference & Network Models\nModule 4 wraps up our work with SNA and examines recent advances in inferential statistics that can be used to make predictions from social network data and test hypotheses we have about a network of interest. Through our Essential Readings, we’ll learn about different techniques that make use of simulations to model network data and how these statistical models are used to address questions that more completely reflect the complexity of educational settings. For example, our SNA Case Study: Birds of a Feather Lead Together is inspired by the work of Daly and Finnigan (2011) makes use of Exponential Random Graph Models (ERGMs) to examine social processes (e.g. reciprocity and homophily) that might explain how school and district-level leaders select peers for collaboration or confidential exchanges. Finally, the Models & Inference Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nNetwork Inference & Applications\n\n\n\nCode Along\nIntro to ERGMs\n\n\n\nReadings &\nDiscussion\nNetwork Modeling & Inference\n\n\n\nCase Study\nBirds of a Feather Lead Together (Answer Key)\n\n\n\nBadge\nModels & Inference",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#microcredential",
    "href": "curriculum-network-analysis.html#microcredential",
    "title": "Social Network Analysis",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the SNA Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your SNA Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a social network context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\nMicrocredential\nSocial Network Analysis and Education",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "institute-intro.html",
    "href": "institute-intro.html",
    "title": "Goals and Objectives",
    "section": "",
    "text": "As the use of digital teaching and learning resources continues to expand, the volume and variety of data available to researchers presents new opportunities for understanding and improving STEM education. The LASER Institute aims to increase the capacity of early and mid-career scholars to leverage new data sources and apply advanced methods to support their research and teaching. Located at the Friday Institute for Educational Innovation, the LASER Institute is a collaborative effort between North Carolina State University, University of Pennsylvania, University of Florida and the University of Tennessee, Knoxville.\nThe LASER Institute focuses on building the capacity of scholars to conduct high-quality research in three primary domains:\n\nDisciplinary Knowledge: Scholars will deepen their understanding of LA methodologies, literature, applications and ethical issues as they relate to STEM education and equity.\nTechnical Skills: Scholars will develop proficiency with R, Python, Quarto, GitHub and other tools used for collaboration, reproducible research and computational analyses.\nSocial Capital: Scholars will expand their professional networks, connecting with researchers and experts in LA related fields, as well as other scholars focused on STEM education."
  },
  {
    "objectID": "instruction-intro.html",
    "href": "instruction-intro.html",
    "title": "Teaching with LASER",
    "section": "",
    "text": "Coming soon!",
    "crumbs": [
      "Home",
      "Instruction",
      "Teaching with LASER"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html",
    "href": "curriculum-knowledge-tracing.html",
    "title": "Knowledge Tracing",
    "section": "",
    "text": "The Knowledge Tracing Modules are designed to provide LASER Scholars with a comprehensive understanding and hands-on experience in various knowledge tracing methods used in digital learning platforms. Beginning with Bayesian Knowledge Tracing (BKT), scholars will build and explore classic BKT models using Python, gaining insights into its application across learning scenarios. The program then introduces Performance Factor Analysis (PFA) and Logistic Knowledge Tracing (LKT), where scholars will clean datasets and build LKT models, learning to analyze student performance involving multiple skills. Next, the modules cover Item Response Theory (IRT), equipping scholars with the principles and skills to validate educational assessments. Finally, the we wrap up this unit by diving into Deep Knowledge Tracing (DKT), where scholars will engage with deep neural network models, understanding their strengths and limitations. Throughout the modules, case studies, essential readings, and badge activities in ASSISTments will reinforce learning and application, preparing scholars to utilize these techniques effectively in educational research and practice.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-1-bayesian-knowledge-tracing",
    "href": "curriculum-knowledge-tracing.html#module-1-bayesian-knowledge-tracing",
    "title": "Knowledge Tracing",
    "section": "Module 1: Bayesian Knowledge Tracing",
    "text": "Module 1: Bayesian Knowledge Tracing\nBayesian Knowledge Tracing (BKT) (Corbett and Anderson 1994) is the most widely used student knowledge modeling framework within digital learning platforms. The BKT model provides decent-quality predictions of future performance within or outside the learning systems, interpretable models, meaningful parameters, and the ability to be applied to a range of learning situations. The goal of our Essential Readings and Case Study is to help LASER Scholars gain a theoretical understanding and practical experience with BKT. Our BKT Case Study is based on Zambrano, Zhang, and Baker (2024). You will use Python to build classic BKT models and explore some of the variations. Finally, you will complete the BKT Badge activity in ASSISTments and develop research questions utilizing a Large Language Model.\n\n\n\n\nConceptual\nOverview\nBayesian Knowledge Tracing\n\n\n\nCode Along\nBKT with ASSISTmentsBKT-BF walkthrough-PCBKT-BF walkthrough Mac\n\n\n\nReadings &\nReflection\nEssential Readings\n\n\n\nCase Study\nBayesian Knowledge Tracing with Python | Answer Key\n\n\n\nBadge\nApplying BKT in Practice",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-2-performance-factor-analysis",
    "href": "curriculum-knowledge-tracing.html#module-2-performance-factor-analysis",
    "title": "Knowledge Tracing",
    "section": "Module 2: Performance Factor Analysis",
    "text": "Module 2: Performance Factor Analysis\nModule 2 introduces Performance Factor Analysis (PFA) and logistic knowledge tracing (LKT) as alternative knowledge tracing methods. LKT utilizes Logistic Regression to investigate students’ performance. Unlike BKT, each item may involve multiple skills or knowledge components (KC). With the case study, you will learn to clean the dataset and build an LKT model. Our case study is based on the work of Tirronen and Tirronen (2020). This paper discusses the application of LKT in the programming education field and the case study will guide you to practice building your LKT model in R with the example dataset. Like module 1, you will complete the LKT Badge activity in ASSISTments and develop research questions utilizing a Large Language Model.\n\n\n\n\nConceptual\nOverview\nLogistic Knowledge Tracing and PFA\n\n\n\nCode Along\nLKT walkthrough\n\n\n\nReadings &\nReflection\nEssential Readings\n\n\n\nCase Study\nPFA case study\n\n\n\nBadge\nLTK and PFA with ASSISTments",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-3-item-response-theory",
    "href": "curriculum-knowledge-tracing.html#module-3-item-response-theory",
    "title": "Knowledge Tracing",
    "section": "Module 3: Item Response Theory",
    "text": "Module 3: Item Response Theory\nModule 3 wraps discuss Item Response Theory, a classic approach for assessment in tests. It is used to assess students’ current knowledge of a topic and it assumes no learning is occurring between items. Through exploring foundational principles, and building models in the case study, this module will equip you with valuable skills to understand the validity of educational assessments. Finally, the badge activity will help you reflect on how these techniques could be applied to research and practice.\n\n\n\n\nConceptual\nOverview\nItem Response Theory and ELO\n\n\n\nCode Along\nComing soon!\n\n\n\nReadings &\nDiscussion\nEssential Readings\n\n\n\nCase Study\nIRT in R\n\n\n\nBadge\nApply IRT in practice",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-4-deep-knowledge-tracing",
    "href": "curriculum-knowledge-tracing.html#module-4-deep-knowledge-tracing",
    "title": "Knowledge Tracing",
    "section": "Module 4: Deep Knowledge Tracing",
    "text": "Module 4: Deep Knowledge Tracing\nModule 4 discusses the application of deep neural networks in knowledge tracing, called Deep Knowledge Tracing (DKT). It is a growing area and has dozens of variants. While deep neural networks are becoming popular and every paper claims good performance, we must be cautious and carefully understand this technique and its strengths and weaknesses before using it. Our essential readings and case studies cover selected current issues and approaches in Deep Knowledge Tracing (DKT). In the hands-on activities, you’ll be working to add a dataset to the implementation of the DKT model from Gervet et al. (2020). Finally, the badge activity will help you reflect on how these techniques could be applied to research and practice.\n\n\n\n\nConceptual\nOverview\nIntro to Deep Knowledge Tracing\n\n\n\nCode Along\nComing soon!\n\n\n\nReadings &\nDiscussion\nEssential Readings\n\n\n\nCase Study\nDKT in Python\n\n\n\nBadge\nApply DKT in Practice",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#microcredential",
    "href": "curriculum-knowledge-tracing.html#microcredential",
    "title": "Knowledge Tracing",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the Knowledge Tracing Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your KT Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a KT context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\n\n\n\n\n\nMicrocredential\nComing soon!",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html",
    "href": "curriculum-la-workflow.html",
    "title": "Learning Analtyics Workflow",
    "section": "",
    "text": "The Learning Analytics Workflow modules are designed to equip STEM education researchers with the skills to apply these analytical methods to better understand and enhance student learning and educational environments. The modules offer a comprehensive overview of the learning analytics process, starting with the characteristics of educational data and progressing through data visualization, analytical methods, and communication of findings. The presentations, readings, and case studies for each module draw from leading texts, such as Learning Analytics Goes to School (Krumm, Means, and Bienkowski 2018), as well as current research in the field, providing participants with both theoretical knowledge and practical experience. Scholars will engage in hands-on coding exercises using R and Python, tailored to their respective programming preferences, ensuring they gain practical skills in data preparation, visualization, modeling, and communication.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analtyics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-1-characteristics-of-data",
    "href": "curriculum-la-workflow.html#module-1-characteristics-of-data",
    "title": "Learning Analtyics Workflow",
    "section": "Module 1: Characteristics of Data",
    "text": "Module 1: Characteristics of Data\nIn Module 1, scholars will learn about different types of learning environments and the characteristics of data commonly used in educational research. The module offers an introduction to the fundamental concepts of learning analytics, tailored for those new to the field or seeking to enhance their basic R or Python programming skills, particularly within STEM education contexts. Scholars will examine various data types, including interaction between instructors and students, administrative and demographic data, and student affectivity, each crucial for developing educational strategies. The hands-on component involves navigating the initial steps of the Learning Analytics workflow, such as preparing data, installing necessary packages, loading data sets, and inspecting data structures. By the end of the module, participants will have a practical understanding of how to apply these concepts through coding exercises, setting the stage for advanced analytical tasks in future modules. The Data Prep badge provides an opportunity to show your skills using the case study data or a choice of data to wrangle using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nCharacteristics of Data in Learning Analytics\n\n\n\nCode Along\nPreparing for Research and Wrangling Data in R | Python\n\n\n\nReadings &\nReflection\nChapter 2: Data Used in Educational Data-Intensive Research\n\n\n\nCase Study\nThe Data-Intensive Research Workflow | R Key | Python Key\n\n\n\nBadge\nFoundations of Learning Analytics",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analtyics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-2-the-power-of-data-viz",
    "href": "curriculum-la-workflow.html#module-2-the-power-of-data-viz",
    "title": "Learning Analtyics Workflow",
    "section": "Module 2: The Power of Data Viz",
    "text": "Module 2: The Power of Data Viz\nIn Module 2, scholars explore the vital role of data visualization in learning analytics. This module underscores how visual representations of data can significantly simplify the complexity of educational data, making it more comprehensible and accessible for analysis. Scholars learn to appreciate the benefits of visualization in enhancing understanding, promoting engagement, aiding decision-making, and improving communication. The module covers various types of data visualizations, such as bar charts, line graphs, scatter plots, heatmaps, and network diagrams, each chosen for their effectiveness in illustrating specific data relationships and patterns. Real-world examples are provided to showcase practical applications and the impact of effective data visualization in educational contexts. Best practices are also discussed, emphasizing the importance of knowing the audience, opting for simple designs, choosing the correct types of visualizations, providing contextual clarity, using colors strategically, and iterating based on feedback to refine the visual outputs. The Exploratory LA badge provides an opportunity to show your skills using case study data or your choice of data to visualize using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nThe Power of Data Visualization\n\n\n\nCode Along\nExploratory Data Analysis Basics with R | Python\n\n\n\nReadings &\nReflection\nChapter 4: Legal and Ethical Issues in Learnign Analytics\n\n\n\nCase Study\nIntro to Exploratory Data Analysis | R Key | Python Key\n\n\n\nBadge\nData Visualization Basics",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analtyics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-3-learning-analytics-methods",
    "href": "curriculum-la-workflow.html#module-3-learning-analytics-methods",
    "title": "Learning Analtyics Workflow",
    "section": "Module 3: Learning Analytics Methods",
    "text": "Module 3: Learning Analytics Methods\nIn Module 3, scholars explore a variety of methods used in learning analytics. The session begins by revisiting basic concepts about the types and characteristics of data in LA. It covers five main analytical methods: predictive analytics, social network analysis, discourse analysis, text analysis, and multimodal analysis. Predictive analytics aims to forecast student performance and enhance intervention strategies. Social network analysis examines social interactions to identify key influencers and optimize collaborative learning. Discourse analysis investigates communication within educational settings to understand student engagement in critical thinking. Text analysis applies natural language processing to assess and provide feedback on text-based assignments. Lastly, multimodal analysis integrates various data sources to provide a comprehensive view of the learning process, supporting personalized educational experiences. This overview equips scholars with the knowledge to apply these methods effectively in educational research and practice. The Modeling badge provides an opportunity to show your skills using case study data or your choice of data to model using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nMethods Used in Learning Analytics\n\n\n\nCode Along\nModeling Basics with R | Python\n\n\n\nReadings &\nDiscussion\nChapter 3: Methods Used in Learning Analytics\n\n\n\nCase Study\nIntroduction to Modeling | R Key | Python Key\n\n\n\nBadge\nTBD",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analtyics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-4-data-products",
    "href": "curriculum-la-workflow.html#module-4-data-products",
    "title": "Learning Analtyics Workflow",
    "section": "Module 4: Data Products",
    "text": "Module 4: Data Products\nIn Module 4, scholars will learn to communicate their analytical findings effectively, focusing on creating publication-ready products and considering ethical aspects of data presentation. They will be introduced to strategies for engaging education stakeholders through compelling data storytelling, ensuring the message is clear and accessible. The course also delves into the preparation of various communication mediums using tools like R Markdown and Flexdashboard to model and communicate insights. Additionally, this module emphasizes the importance of addressing ethical considerations such as data privacy, bias, and inclusive practices to ensure responsible use of data in educational settings. This framework prepares scholars to craft their messages thoughtfully, considering both their audience and the ethical dimensions of data use. The Communication badge provides an opportunity to show your skills using case study data or your choice of data to develop a dashboard using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nCommunicating with Stakeholder\n\n\n\nCode Along\nData Products with R | Python\n\n\n\nReadings &\nDiscussion\nChapter 7: Five Phases of Data-Intensive Improvement\n\n\n\nCase Study\nBuilding a Basic Data Dashboard | R Key | Python Key\n\n\n\nBadge\nTBD",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analtyics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#microcredential",
    "href": "curriculum-la-workflow.html#microcredential",
    "title": "Learning Analtyics Workflow",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the LAW Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your LAW Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a social network context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\n\n\n\n\n\nMicrocredential",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analtyics Workflow"
    ]
  },
  {
    "objectID": "institute-goals.html",
    "href": "institute-goals.html",
    "title": "Goals and Objectives",
    "section": "",
    "text": "LASER: Broadening Education in Advanced Methods (LASER BEAM) is the next phase of the LASER Institute funded by NSF (DRL-2321128, and DRL-2321129). LASER BEAM builds upon the prior NSF-funded LASER Institute DRL-2025090, which aims to increase the number of education research capable of leveraging new sources of data and data-intensive research methods to understand and improve student learning. The LASER Institute is a year-long professional development program for early- and mid-career researchers consisting of two core components:",
    "crumbs": [
      "Home",
      "Institute",
      "Goals and Objectives"
    ]
  },
  {
    "objectID": "institute-goals.html#institute-goals",
    "href": "institute-goals.html#institute-goals",
    "title": "Goals and Objectives",
    "section": "Institute Goals",
    "text": "Institute Goals\nThe LASER Institute aims to increase the capacity of early and mid-career scholars to leverage new data sources and apply advanced methods to support their research and teaching. Located at the Friday Institute for Educational Innovation, the LASER Institute is a collaborative effort between North Carolina State University, University of Pennsylvania, University of Florida and the University of Tennessee, Knoxville.\nThe LASER Institute and associated curriculum materials shared on this website are designed to build the capacity of participating scholars in three core areas:\n\nDisciplinary Knowledge: Scholars will deepen their understanding of LA methodologies, literature, applications and ethical issues as they relate to STEM education and equity.\nTechnical Skills: Scholars will develop proficiency with R/Python, Quarto, GitHub and other tools used for collaboration, reproducible research and computational analysis.\nSocial Capital: Scholars will expand their professional networks, connecting with researchers and experts in LA related fields, as well as other scholars focused on STEM education.",
    "crumbs": [
      "Home",
      "Institute",
      "Goals and Objectives"
    ]
  },
  {
    "objectID": "institute-goals.html#learning-objectives",
    "href": "institute-goals.html#learning-objectives",
    "title": "Goals and Objectives",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe LASER curriculum is designed to help faculty teach current and emerging STEM education researchers to:\n\nUnderstand which research questions/issues appropriately addressed by LA as compared to other analytical approaches and advanced methods;\nIdentify relevant sources of education data to address both theoretical and practical issues in STEM education;\nApply computational techniques (e.g., machine learning and text mining) using a choice of packages (R or Python) to prepare, explore, and model education data;\nEvaluate the technical feasibility, ethical issues, and societal constraints in using analytics to support STEM teaching and learning;\nCollaborate with educational organizations to help them learn from their own data and identify new ways to support students.",
    "crumbs": [
      "Home",
      "Institute",
      "Goals and Objectives"
    ]
  },
  {
    "objectID": "institute-goals.html#institute-activities",
    "href": "institute-goals.html#institute-activities",
    "title": "Goals and Objectives",
    "section": "Institute Activities",
    "text": "Institute Activities\nTo help accomplish these goals and objectives, LASER BEAM aims to build on prior efforts and scale them to a much greater degree by through the following activites:\n\nDevelop a modular curriculum adaptable to instructors’ needs. LASER BEAM aims to create a modular curriculum composed of 25-30 distinct instructional modules that can be incorporated into semester-long courses or used individually for workshops, webinars, or other training venues. To ensure that materials can be readily adapted and implemented in a wide range of contexts, evaluation efforts will focus in part on gathering ongoing feedback from instructors to improve the curriculum.\nPrepare faculty to learn from and teach with LASER curriculum resources. Faculty will participate in an intensive, week-long Summer Institute with ongoing supports during the academic year. Both of these componetns are designed to prepare them in these advanced methods and to incorporate curriculum resources into graduate-level programs, courses, or workshops at their home university or research institution.\nBroaden educational opportunities in advanced methods. Ultimately, LASER BEAM aims to greatly expand the number of STEM education researchers who have the expertise necessary to leverage LA and big data to support their research. To that end, the project team will provide faculty ongoing support throughout the academic year to pilot curriculum resources within graduate-level programs, courses, or workshops at their local university or research institution.",
    "crumbs": [
      "Home",
      "Institute",
      "Goals and Objectives"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "The Learning Analytics in STEM Education Research (LASER) Institute is a year-long professional development program for early and mid-career scholars funded by the National Science Foundation. The LASER Institute aims to increase the number of early and mid-career scholars capable of leveraging new data sources and applying computational research methods (e.g., network analysis, text mining and machine learning) to support their existing research and develop new lines of inquiry.\nTo learn more about how you can become involved as a participating scholar, guest speaker, or curriculum contributor, visit the Institute section of this website for an overview of the program. For more detailed information about eligibility, application process, team members, and past scholars, visit our project page at go.ncsu.edu/laser-institute."
  },
  {
    "objectID": "index.html#the-laser-curriculum",
    "href": "index.html#the-laser-curriculum",
    "title": "Welcome!",
    "section": "The LASER Curriculum",
    "text": "The LASER Curriculum\nThis website contains all the materials needed to teach with, and learn from, the curriculum developed for the LASER Institute.\n\nThe Curriculum section includes instructional modules for computational methods commonly employed in Learnign Anlaytics. Each module includes slide decks, essential readings, discussion questions, code-alongs, case studies, and assessment activities.\nThe Instruction section provide supporting materials for instructors interested in adopting or adapting the LASER curriculum for their own students. This section includes information and resources on pedagogical design, computing infrastructure, sample teaching formats, and logistics for using LASER curriculum materials in your own webinar, workshops, or course."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Welcome!",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe LASER This material is based upon work supported by the National Science Foundation under Grant No. DRL-2025090, DRL-2321128, and DRL-2321129."
  },
  {
    "objectID": "what-is-la.html",
    "href": "what-is-la.html",
    "title": "What is Learning Analytics?",
    "section": "",
    "text": "Learning Analytics is the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs. As a research and teaching field, Learning Analytics sits at the convergence of:\nLearning Analytics builds on these well established disciplines, but also seeks to leverage new opportunities through new forms of digital data computational analysis techniques from data science and AI.\nVisit the Society for Learning Analytics Research to read more or watch the 2021 LASER Institute keynote is by Dr. Alyssa Wise, professor of technology and education and director of the Learning Incubator: A Vanderbilt Endeavor (LIVE), and former professor of learning sciences and educational technology and director of New York University’s Learning Analytics Research Network (LEARN).",
    "crumbs": [
      "Home",
      "Institute",
      "What is Learning Analytics?"
    ]
  },
  {
    "objectID": "what-is-la.html#laser-institute-keynote",
    "href": "what-is-la.html#laser-institute-keynote",
    "title": "What is Learning Analytics?",
    "section": "LASER Institute Keynote",
    "text": "LASER Institute Keynote",
    "crumbs": [
      "Home",
      "Institute",
      "What is Learning Analytics?"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Our Standards",
    "text": "Our Standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Responsibilities",
    "text": "Enforcement Responsibilities\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Guidelines",
    "text": "Enforcement Guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n1. Correction\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n2. Warning\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n3. Temporary Ban\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n4. Permanent Ban\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https:// www.contributor-covenant.org/translations."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\n\n__Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\n\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\n\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\n\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "curriculum-text-mining.html",
    "href": "curriculum-text-mining.html",
    "title": "Text Mining",
    "section": "",
    "text": "The transition to digital learning has made available new sources of data, providing researchers new opportunities for understanding and improving STEM learning. Data sources such as digital learning environments and administrative data systems, as well as data produced by social media websites and the mass digitization of academic and practitioner publications, hold enormous potential to address a range of pressing problems in STEM Education, but collecting and analyzing text-based data also presents unique challenges. Text mining labs address the following critical questions:",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-1-tidy-text-word-counts-tm-basics",
    "href": "curriculum-text-mining.html#module-1-tidy-text-word-counts-tm-basics",
    "title": "Text Mining",
    "section": "Module 1: Tidy Text & Word Counts (TM Basics)",
    "text": "Module 1: Tidy Text & Word Counts (TM Basics)\nThis module is a gentle introduction to getting our text “tidy” so we can perform some basic word counts, look at words that occur at a higher rate in a group of documents, examine words that are unique to those document groups, and create visualizations such as word cloud. The focus of our Essential Readings and case study in this lab is to help LASER Scholars gain a general understanding of key text mining concepts and terminology, as well as develop a basic comfort level with quantifying text data and working with text data. Our Text Mining Case Study: What aspects of online professional development offerings do teachers find most valuable? is guided by the work from Friday Institute and it examines teachers’ experiences in professional development. Finally, the Intro to Text Mining Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nReflection\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-2-public-sentiment-and-school-reform-dictionary-methods",
    "href": "curriculum-text-mining.html#module-2-public-sentiment-and-school-reform-dictionary-methods",
    "title": "Text Mining",
    "section": "Module 2: Public Sentiment and School Reform (Dictionary Methods)",
    "text": "Module 2: Public Sentiment and School Reform (Dictionary Methods)\nThis module moves beyond basic concepts of text mining and takes a closer look at a dictionary-based text mining technique, sentiment analysis. Our Essential Readings examine the topic of opinion mining or sentiment analysis. This technique is very helpful for us to understand people’s opinions about things such as a policy. Our Text mining Case Study: Do the public like NGSS? investigates the public sentiment expressed toward the Next Generation Science Standards (NGSS) and compares the sentiment for NGSS and Common Core State Standards using X (twitter) data. This study by Rosenberg et al. (2021) can be found at https://osf.io/xymsd/. Finally, the Sentiment Analysis Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nReflection\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-3-large-language-models-for-qualitative-analysis",
    "href": "curriculum-text-mining.html#module-3-large-language-models-for-qualitative-analysis",
    "title": "Text Mining",
    "section": "Module 3: Large Language Models for Qualitative Analysis",
    "text": "Module 3: Large Language Models for Qualitative Analysis\nThis module wraps up our work with text mining and examines recent advances in using large language models to code qualitative data (i.e., interview transcripts, group discussions, and open-ended responses). Through our essential readings, we’ll learn about this technique. Our Text Mining Case Study: What are high school students’ machine learning literacy before and after participating in an AI curriculum? is inspired by the need to assess machine learning literacy and use automated assessment for real-time intervention in the field of AI education. Finally, the Large Language Model Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nDiscussion\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-4-topic-modeling-in-mooc-eds",
    "href": "curriculum-text-mining.html#module-4-topic-modeling-in-mooc-eds",
    "title": "Text Mining",
    "section": "Module 4: Topic Modeling in MOOC-Eds",
    "text": "Module 4: Topic Modeling in MOOC-Eds\nThis module focuses on identifying “topics” by examining how words cohere into different latent, or hidden, themes based on patterns of co-occurrence of words within documents. Our Essential Readings introduces this unsupervised machine learning technique. Our Text Mining Case Study: What are participants discussing in forums? is guided by the work from Friday Institute and it explores ideas or issues that emerged in the discussion forums in a MOOC-ed course. You can learn more about the work here (https://www.learntechlib.org/p/195234/). Finally, the Topic Modeling Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nDiscussion\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#microcredential",
    "href": "curriculum-text-mining.html#microcredential",
    "title": "Text Mining",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the TM Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your TM Microcredential, you must demonstrate your ability to formulate a relevant research question for text mining, effectively manage and analyze text data, and clearly communicate your key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\n\n\n\n\n\nMicrocredential",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "institute-workshop.html",
    "href": "institute-workshop.html",
    "title": "Summer Workshop",
    "section": "",
    "text": "LASER BEAM participants will begin their program with an intensive 5-day summer training program at the FI, taught by NC State and Penn faculty and with invited presentations from Advisory Board members. Each Summer Institute will take place in July with pre-workshop preparation (e.g., introductions and needs assessment) for participants beginning earlier that spring. To attend to the needs of STEM education faculty and researchers with varying degrees of expertise in LA, the Summer Institute will provide both a beginner track and an advanced track to support faculty development, with approximately half of the participants in each track. The proposed Summer Institute schedule outlined in Table 2 provides an overview of the sequence of activities currently planned, recognizing that some adjustments will be necessary based on the needs assessment and specific modules participants are interested in teaching and/or learning from. Each of these activities is described in more detail below.\n\nSummer Institute Schedule\n\n\n\n\n\n\n\n\n\n\n\nEST\nMonday\nTuesday\nWednesday\nThursday\nFriday\n\n\n9:00 - 9:30\nLASER Welcome\nCommunity Building\nCommunity Building\nCommunity Building\nCommunity Building\n\n\n9:40 - 11:00\nModule Overview\nModule Session 1\nModule Session 2\nModule Session 3\nModule Session 4\n\n\n11:15 - 12:30\nPedagogy Session\nModule Session 1 cont.\nModule Session 2 cont.\nModule Session 3 cont.\nModule Session 4 cont.\n\n\n1:30 - 2:45\nGuest Speaker\nGuest Speaker\nGuest Speaker\nGuest Speaker\nGuest Speaker\n\n\n3:00 - 3:45\nPedagogy Session\nPedagogy Session\nPedagogy Session\nPedagogy Session\nEvaluation\n\n\n4:00 - 5:00\nDesign Session\nDesign Session\nDesign Session\nDesign Session\nEarly Exit\n\n\n\n\n\nPre-Institute Preparation\nPrior to the Summer Institute, participants will complete a needs assessment to identify their teaching interests, experience with software packages, and skills and knowledge in relation to LA and advanced methods. This assessment will be used to identify the appropriate track for their Summer Institute experience and help guide the content, structure and sequence of their 5-day professional development. Instructors on the beginner track will also engage in pre-institute tutorials beginning in May and which must be completed prior to the workshop to demonstrate their preparation and commitment to LASER BEAM. Finally, all participants will engage in an initial community building activity designed to familiarize participants with the social platform that will be used throughout LASER BEAM as part of the Online Community and provide them with an opportunity to get to know each other prior to the Summer Institute.\n\n\nCommunity Building\nThe research and the project team’s experience leading faculty and educator training programs suggest community building activities are critical in supporting and affirming sustained participation in LA and data science initiatives, particularly for novice learners and scholars from minoritized groups (Arif et al., 2021). Consequently, LASER BEAM will incorporate identity-affirming activities each day of the workshop to help participants learn more about each other and create a sense of community (Booth & Kellogg, 2015; Deglau & O’Sullivan, 2006). By sharing their backgrounds, interests, and experiences, participants will identify commonalities and differences. This will create a space for participants to learn from each other and build on each other’s strengths.\n\n\nPedagogy Sessions\nParticipants in both the beginnerand advancedtracks will engage in whole group sessions to support them in adapting materials for their own instructional programs. Sessions will focus on a range of topics, from understanding the design principles behind the LASER BEAM curriculum to setting up the infrastructure necessary for learners to fully participate in module activities. Pedagogy sessions throughout the week will focus on the nuts and bolts of teaching the curriculum, including topics such as tools and approaches for facilitating in-person and online discussion, assessment and grading of assignments, and logistics for instructional delivery. For example, on Day 1 (Monday) participants are introduced to Posit Cloud, a powerful set of data science and instructional tools that can be accessed through an internet browser and used for assigning, supporting, and assessing instructional activities such as the interactive coding case studies and tutorials highlighted in Section 2c.\n\n\nModule Sessions\nModule sessions will be conducted in small groups and differentiated for participants in the beginnerand the advanced track based upon the needs assessment administered prior to the Summer Institute. These sessions will focus on the instructional materials from which participants will both learn from and use to train learners at their home institutions. Participants in the beginner track will focus on 4 introductory modules to develop their foundational knowledge and skills (see Section 2c) necessary for more advanced methods. Advanced track participants will engage in 4 module sessions focused on more advanced topics such as text classification and deep knowledge tracing. Sessions will be facilitated by members of the project team, who will model instructional best practices for use of these materials and participants in both tracks will work through select module activities just as would be expected from the students and faculty they plan to teach. Additionally, module sessions will be offered in an online format through workshops in the fall and spring (see Online Community section). This will allow the project team to both address topics not covered during the summer institute and to model instructional delivery in a purely online context.\n\n\nDesign Sessions\nEach day will end with small group activities to assist participants in designing a customized instructional plan at their home institutions, where they consider how to incorporate curriculum resources into their own contexts. The project team will collaborate with participants to choose relevant modules and activities, effective teaching methods (pedagogy), and suitable technology from our training resources that meet the needs of their learners. The team will also work with participants in aligning the chosen LA topics, pedagogy, and technology with the learners’ needs to ensure the modules are tailored to address the unique needs and preferences of their learners.\n\n\nGuest Speakers\nThese sessions will draw upon the backgrounds and expertise of our Advisory Board members and other invited guests who have taught courses, workshops, and training events focused on LA and related methods. Sessions will reinforce topics introduced in our module and pedagogy sessions, and help participants envision how LASER BEAM curriculum materials and activities might be adapted to fit their own contexts and institutional programs.",
    "crumbs": [
      "Home",
      "Institute",
      "Summer Workshop"
    ]
  },
  {
    "objectID": "institute-online.html",
    "href": "institute-online.html",
    "title": "Online Community",
    "section": "",
    "text": "Ongoing support is provided to participants during the academic year to continue their professional learning and ensure they can successfully carry out instructional plans at their home institutions. The project team provides a range of activities designed to support participants and inform curriculum refinement throughout the year. These following are guided by findings from our prior research found to be strongly associated with successful online communities: \n\nMonthly Check-Ins\nThroughout fall and spring, the project team will facilitate formal monthly check-ins with participants on progress made towards implementing instructional plans developed duringthe Summer Workshop. The check-ins will also be used to gather feedback on curricular modules used by instructors. Guest speakers from our advisory board and other invited guests will also lead sessions on LA topics during check-ins. These sessions will be informed by the community, as well as more specialized topics in advanced methods.\n\n\nVirtual Module Sessions\nThese session are offered several times each month so participants can learn about research methods they were unable to experience during the Summer Institute, as well to model instructional use of the modules in a fully online context. The workshops are led by members of the project team as well as by past LASER Scholars.\n\n\nAsynchronous Activities\nFacilitated discussion channels and informal Q&As are hosted on our Slack workspace, which includes both current and past participants from prior LASER Institute cohorts. Discussions focus on shared problems of practice such as adapting instructional modules to local contexts or working with students who have limited programming experience, as well as topics related to module content such as R packages, conceptual overviews, and essential readings. \n\n\nResource Repositories\nA key deliverable of this grant is a freely available website that houses all the curriculum materials needed to teach, and learn from, the LASER curriculum. These materials consist of both project team and member-generated content hosted on GitHub and a new curriculum website currently under development. These website include materials for each module as well as supporting materials for instructors such as pedagogical tips, information on computing infrastructure, technology stack, and logistics for set up.",
    "crumbs": [
      "Home",
      "Institute",
      "Online Community"
    ]
  },
  {
    "objectID": "curriculum-orientation.html",
    "href": "curriculum-orientation.html",
    "title": "LASER Orientation",
    "section": "",
    "text": "Instructional materials for the LASER Orientation and other modules are linked below and come in three main flavors:",
    "crumbs": [
      "Home",
      "Curriculum",
      "LASER Orientation"
    ]
  },
  {
    "objectID": "curriculum-orientation.html#orientation-module-the-laser-toolkit",
    "href": "curriculum-orientation.html#orientation-module-the-laser-toolkit",
    "title": "LASER Orientation",
    "section": "Orientation Module: The LASER Toolkit",
    "text": "Orientation Module: The LASER Toolkit\nThe Orientation Module is designed to get learners up and running with the concepts, tools, and processes that guide the LASER curriculum. The orientation begins with a Conceptual Overview focused on the benefits of reproducible research (Gandrud 2013) and tools used by LASER to for this purpose. The Code-Along is a gentle introduction to R/Python and the data-intensive research workflow introduced by Krumm, Means, and Bienkowski (2018) and covered in greater depth by . The coding Case Study expands upon the code-along and introduces working with Quarto, an open-source scientific and technical publishing system. Finally, learners earn their first LASER Badge by publishing their work to the web.\n\n\n\n\nConceptual\nOverview\nThe LASER Toolkit & Reproducible Research\n\n\n\nCode Along\nThe Data-Intensive Research Workflow in R | Python\n\n\n\nReadings &\nReflection\nReproducible Research & DIR Workflow\n\n\n\nCase Study\nA Coding Case Study with Quarto | R Key | Python Key\n\n\n\nBadge\nLASER Orientation Badge",
    "crumbs": [
      "Home",
      "Curriculum",
      "LASER Orientation"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html",
    "href": "curriculum-machine-learning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Introduction…",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-1-name",
    "href": "curriculum-machine-learning.html#module-1-name",
    "title": "Machine Learning",
    "section": "Module 1: NAME",
    "text": "Module 1: NAME\nModule 1 overview…\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nReflection\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-2-name",
    "href": "curriculum-machine-learning.html#module-2-name",
    "title": "Machine Learning",
    "section": "Module 2: NAME",
    "text": "Module 2: NAME\nModule 2 overview…\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nReflection\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-3-name",
    "href": "curriculum-machine-learning.html#module-3-name",
    "title": "Machine Learning",
    "section": "Module 3: NAME",
    "text": "Module 3: NAME\nModule 3 overview…\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nDiscussion\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-4-name",
    "href": "curriculum-machine-learning.html#module-4-name",
    "title": "Machine Learning",
    "section": "Module 4: NAME",
    "text": "Module 4: NAME\nModule 4 overview…\n\n\n\n\n\n\n\n\n\nConceptual\nOverview\n\n\n\n\nCode Along\n\n\n\n\nReadings &\nDiscussion\n\n\n\n\nCase Study\n\n\n\n\nBadge",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#microcredential",
    "href": "curriculum-machine-learning.html#microcredential",
    "title": "Machine Learning",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the TM Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your TM Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a social network context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\nMicrocredential",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#references",
    "href": "curriculum-machine-learning.html#references",
    "title": "Machine Learning",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Home",
      "Curriculum",
      "Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-design.html",
    "href": "curriculum-design.html",
    "title": "Modular by Design",
    "section": "",
    "text": "The LASER Institute curriculum is modular by design and consists of instructional modules that can be assembled into multiple distinct semester-long courses, incorporated into existing courses, or used individually for workshops, webinars, or other learning experiences. This design enables instructors to tailor content and activites for learners with different disciplinary backgrounds and to incorporate them as needed into new or existing programs, thereby expanding high-quality educational opportunities in LA for institutions that lack the resources to create these materials from scratch.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-design.html#design-principles",
    "href": "curriculum-design.html#design-principles",
    "title": "Modular by Design",
    "section": "Design Principles",
    "text": "Design Principles\nThe guiding design principle of the LASER BEAM curriculum, setting it apart from existing programs in learning analytics and educational data science, is a close connection between exemplary STEM education research and hands-on experience analyzing real-world datasets. This connection is essential for building the competencies necessary to carry out high-quality education research in STEM fields and to enable researchers to integrate methodological strategies and practices with theoretical and practical issues in STEM education. Guiding design principles the LASER curriculum include:\n\nResearch Connections. A close connection between exemplary STEM education research and hands-on experience analyzing real-world datasets.\nScaffolded Activities. Activities are carefully scaffolded to ease learners into the conceptual and technical aspects of learning analytics and to gradually release instructor supports.\nHands-On Programming. Experience using modern, industry standard analytic tools like R and Python to carry out essential data science workflow processes.\nReal-World Data. real-world datasets from a wide range of sources such as MOOCs, student information systems, and log data from digital learning platforms.\nTopic Deep Dives. Each Module Opportunities for participants to explore key topics in-depth through Essential Readings and coding Case Studies.\nLowered Barriers. Activities are designed to lower the barriers faced by researchers with little programming experience or research backgrounds in advanced methods.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-design.html#modules-topics",
    "href": "curriculum-design.html#modules-topics",
    "title": "Modular by Design",
    "section": "Modules Topics",
    "text": "Modules Topics\nLASER modules cover a broad range of both introductory and advanced methods frequently leveraged by LA researchers and explicitly illustrate how these methods have been applied in STEM education research. Introductory modules will focus on basic concepts pertaining to each research method and proficiency with software tools commonly employed in LA and data science more broadly (i.e., R, Python, GitHub, APIs) and focus on topics pertaining to data-intensive research workflows (Krumm et al., 2018). Modules addressing advanced methods focus on a range of exploratory and modeling techniques including supervised machine learning, unsupervised learning, relationship mining, topic modeling and LLMs, knowledge tracing and knowledge graphs, and social and epistemic network analysis.\n\n\n\n\n\n\n\n\n\n\nResearch Methods\nModule 1\nModule 2\nModule 3\nModule 4\n\n\n\n\nLA Workflows\nData Wrangling\nExploratory Analysis\nModeling Basics\nData Products\n\n\nSupervised Learning (SL)\nSL Basics\nFeature Engineering \nModel Tuning\nDiagnostic Metrics\n\n\nUnsupervised Methods\nUM Basics\nClustering\nFactor Analysis\nKnowledge Structures\n\n\nText Mining (TM)\nTM Basics\nTopic Modeling\nText Classification\nLarge Language Models\n\n\nRelationship Mining (RM)\nRM Basics\nCorrelation Mining\nAssociation and Sequential Rules\nAssociation Rule Metrics\n\n\nKnowledge Tracing (KT)\nKT Basics\nBKT family \nPFA/LKT families\nDKT family\n\n\nSocial Network Analysis (SNA)\nSNA Basics\nMeasurement\nPositions & Groups\nNetwork Modeling\n\n\nEpistemic Network Analysis (ENA)\nENA Basics\nVisualizing Networks\nQuantitative Analysis\nAdvanced Applications\n\n\n\nInterwoven within and across modules, and as appropriate to each method, are topics designed to deepen learners’ understanding of LA approaches, applications, and legal and ethical issues. Specifically, topics will include but are not limited to reproducible research and open-science standards; types of data used in LA and the methods for their collection; applications of LA to STEM educational contexts such as recommendation and intelligent tutoring systems, adaptive learning and curriculum design, and students at risk of failing a course; and legal and ethical considerations such as student privacy, data ethics and algorithmic bias. In addition, learners are introduced to frameworks and approaches such as research-practice partnerships to prepare them to work closely with educational organizations to improve STEM outcomes at the local, district and state level.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-design.html#module-activities",
    "href": "curriculum-design.html#module-activities",
    "title": "Modular by Design",
    "section": "Module Activities",
    "text": "Module Activities\nEach instructional module consist of carefully scaffolded activities designed to prepare participants for collaborative, data-intensive research, and to lower the barriers faced by scholars with little programming experience or research backgrounds in advanced methods. These activities provide opportunities for participants to explore key topics in-depth and gain hands-on experience using analytic tools like R and Python to carry out essential data science workflow processes, including advanced methods for machine learning and text mining. In each module, participants will also explore how these methods have been applied by researchers in STEM education contexts and work with corresponding real-world datasets from a wide range of sources such as MOOCs, student information systems, and log data from digital learning platforms.\n\nIntroductory Presentations\n\nConceptual Overviews\nEach module includes a presentation(see example) that introduces of key concepts, terminology, and applications as they relate to each corresponding research methods and their associated techniques. Conceptual Overviews are facilitated by instructors and include opportunites for discussions, questions, and practical activities, enabling participants to demonstrate their grasp of the material. This session aims to equip learners with the knowledge to apply these advanced research methods in their work, fostering innovation in STEM education.\n\n\nCode-Alongs\nThe second presentation provides a short but highly structured coding (see example) activity that demonstrates key packages and functions required for specific data analysis techniques highlighted in each unit and an exemplary research study. Both presentations include prompts for discussion to check participant understanding and connect content with their personal and professional research interests. Recorded versions of these presentations, as well as select presentations from Baker’s BDEMOOC, will also be provided on the LASER BEAM website to support independent learners. \n\n\n\nInstructional Deep Dives\n\nReadings & Reflection\nEssential Readings (see example) are curated for participants to help them dive deeper into LA concepts, techniques, and applications introduced in presentation and case studies. Each module also includes an exemplary research paper that illustrates how techniques highlighted in each module have been applied in STEM education contexts. These papers are often used to guide coding case studies and help connect technical skills required for advanced methods with authentic research applications. Accompanying these readings are guiding questions that can be used for personal reflection or to help instructors facilitate discussion and assess their understanding of module content.\n\n\nCoding Case Studies\nCase Study assignments (see example) developed by the project team are interactive coding experiences that can be completed by learners independently or in small groups. These activities demonstrate how key data-intensive research workflow processes (i.e., wrangling, visualizing, summarizing, modeling, and communicating data) featured in exemplary STEM education research studies are implemented in R or Python. Coding case studies also provide a holistic setting to explore important foundational LA topics integral to data analysis such as reproducible research, use of APIs, student privacy, ethical consideration, and diversity and inclusion in STEM education.\n\n\nOnline Tutorials\nOpenly accessible online tutorials are curated for each module and are intended to help learners develop technical proficiency with essential software packages, functions, and programming syntax introduced during conceptual overviews, code-alongs, and case studies. Tutorials include, but are not limited to, interactive R primers, recipes, and cheatsheets available on Posit Cloud, as well as Python and intelligent-tutor based assignments that scaffold students in learning to use learning analytics methods.\n\n\n\nAssessment\n\nBadges\nEach module includes a summative assessment activity designed to help learners reflect on how the concepts and techniques introduced in each lab might apply to their own STEM education research, where they can demonstrate their technical proficiency with the analytical techniques and methods addressed in each unit. Instructors are provided with digital Badges (see example) to award students upon successful completion of assessments. At the instructor’s discretion, badges can be sequenced into microcredentials that can be used to certify learners’ successful demonstration and/or application of LA methods.\n\n\nMicrocredentials\nMicrocredentials are designed for individuals seeking to validate their expertise in learning analytics are are offered for each research methods.To earn a microcredential, participants are required to demonstrate a comprehensive understanding and showcase their ability to effectively utilize learning analytics to gather, analyze, and communciate educational data to support their own research.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-activities.html",
    "href": "curriculum-activities.html",
    "title": "Module Activities",
    "section": "",
    "text": "Activities for each instructional module are informed by lessons learned through PI Kellogg’s LASER Institute and LA Graduate Certificate program, and PI Baker’s experience offering BDEMOOC and other courses for over a decade. Modules will consist of carefully scaffolded activities designed to prepare participants for collaborative, data-intensive research, and to lower the barriers faced by scholars with little programming experience or research backgrounds in advanced methods. These activities will provide opportunities for participants to explore key topics in-depth and gain hands-on experience using analytic tools like R and Python to carry out essential data science workflow processes, including advanced methods for machine learning and text mining. In each module, participants will also explore how these methods have been applied by researchers in STEM education contexts and work with corresponding real-world datasets from a wide range of sources such as MOOCs, student information systems, and log data from digital learning platforms.\n\nInteractive Presentations\n\nEach module contain slide decks for two interactive presentations that provide an overview of key concepts, software packages and functions for data analysis. The first presentation focuses on a conceptual overview of key terminology, techniques, and applications. The second presentation provides a short but highly structured code-along activity that demonstrates key packages and functions required for specific data analysis techniques highlighted in each unit and an exemplary research study. Both presentations include prompts for discussion to check participant understanding and connect content with their personal and professional research interests. Recorded versions of these presentations, as well as select presentations from Baker’s BDEMOOC, will also be provided on the LASER BEAM website to support independent learners. \n\n\nCoding Case Studies\nCase study assignments developed by the project team are interactive coding experiences that can be completed by learners independently or in small groups. These activities demonstrate how key data-intensive research workflow processes (i.e., wrangling, visualizing, summarizing, modeling, and communicating data) featured in exemplary STEM education research studies are implemented in R or Python. Coding case studies also provide a holistic setting to explore important foundational LA topics integral to data analysis such as reproducible research, use of APIs, student privacy, ethical consideration, and diversity and inclusion in STEM education.\n\n\nReadings and Discussion\nEssential readings are curated for participants to help them dive deeper into LA concepts, techniques, and applications introduced in presentation and case studies. Each module includes an exemplary research article that illustrates how LA applications and/or techniques highlighted in each module (e.g., data visualization, topic modeling) have been used in STEM education contexts. These articles are also used to guide coding case studies and help connect technical skills required for advanced methods with authentic research applications. Instructors will be provided guiding questions to help them facilitate discussion among learners and assess their understanding of module content.\n\n\nSoftware Tutorials\nOpenly accessible software tutorials are curated for each module and are intended to help learners develop technical proficiency with essential software packages, functions, and programming syntax introduced during conceptual overviews, code-alongs, and case studies. Tutorials include, but are not limited to, interactive R primers available on Posit Cloud (CITATION) and Python and intelligent-tutor based assignments developed by UPenn that scaffold students in learning to use learning analytics methods (Aleven et al., 2017; Zhou et al., 2021). \n\n\nBadges & Microcredentials\nEach module includes a summative assessment activity designed to help learners reflect on how the concepts and techniques introduced in each lab might apply to their own STEM education research, where they can demonstrate their technical proficiency with the analytical techniques and methods addressed in each unit. Instructors are provided with digital badges to award students upon successful completion of assessments. At the instructor’s discretion, badges can be sequenced into microcredentials that can be used to certify learners’ successful demonstration and/or application of LA methods. Microcredential certificates will also be created for learners who have demonstrated their ability to consider the potential applications and challenges of learning analytics in society. Badging activities and corresponding badges developed for the LASER Institute will be expanded to include new modules created from UPenn materials."
  }
]